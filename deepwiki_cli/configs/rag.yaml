rag:
  embedder:

    provider: dashscope
    model: text-embedding-v4

    # provider: huggingface
    # model: intfloat/multilingual-e5-large-instruct

    api_key: ""
    base_url: ""
    model_kwargs:
      dimensions: 256
      encoding_format: float
    # The qps of dashscope is 10, we need to set the batch size to 10 at most if using dashscope
    batch_size: 10

    sketch_filling: true
    force_embedding: false

  retriever:
    top_k: 20

  hybrid:
    enabled: true
    bm25:
      top_k: 100
      k1: 1.2
      b: 0.75
  
  text_splitter:
      split_by: token
      chunk_size: 256
      chunk_overlap: 32

  # Dynamic splitter configuration - automatically selects appropriate splitter
  dynamic_splitter:
    enabled: false
    parallel: true
    # If batch_size is None, use all available CPU cores. Otherwise, use the specified batch size.
    # Each batch will be processed in parallel.
    batch_size: null
    # Text splitter configuration for natural language documents
    natural_language_splitter:
      split_by: word
      chunk_size: 256
      chunk_overlap: 32
    # Code splitter configuration for source code files
    code_splitter:
      split_by: word
      chunk_size: 256
      chunk_overlap: 32

  code_understanding:
    provider: lingxi
    model: qwen3-8b
    # provider: dashscope
    # model: qwen3-8b
    api_key: ""
    base_url: ""
    batch_size: 50
    model_kwargs:
      temperature: 0.7
      top_p: 0.8
      max_tokens: 2048